{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS620 Project 1\n",
    "## Robert Sellers | October 3, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardian API Article Scraping and Gephi Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[LINK TO VIDEO WALKTHROUGH](https://www.youtube.com/watch?v=HXhjbF6_ZZI&)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code makes use of a connection to the [Guardian API]([http://open-platform.theguardian.com/) in Python, a recursive scraping function into network nodes and edges, and an export into Gephi data format .GDF. The following approach was heavily inspired by the following [GIST](https://gist.github.com/psychemedia/1283684). \n",
    "\n",
    "The logic behind the queries is to export the \"most relevant\" national news for a few nations and compare the general coverage between the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import simplejson\n",
    "import urllib\n",
    "import csv\n",
    "import sys\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#My guardian API key. This is very easy to acquire. Feel free to use this. \n",
    "APIKEY='d8d6f3e6-8a96-46b9-8681-d39b146def8c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is now a block of code that takes in a query (i.e. \"Olympics\"), encodes the query string, extracts the json from the API query result, and recursively generates nodes/edges into a Gelphi file based on the keyword -> article search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def searchGuardian(searchterm):\n",
    "    term='\"'+' '.join([searchterm])+'\"'\n",
    "    enc=urllib.urlencode({'q':term})\n",
    "    API = 'api-key='+APIKEY\n",
    "    show = '&page-size=25&'\n",
    "    tags = '&show-tags=keyword&'\n",
    "    pagesize = '&order-by=relevance&'\n",
    "    queryURL='http://content.guardianapis.com/search?q='+searchterm+tags+show+pagesize+API\n",
    "    #prints the URL for reference\n",
    "    print queryURL\n",
    "    #load the data using simplejson\n",
    "    data = simplejson.load(urllib.urlopen(queryURL))\n",
    "    #size the results \n",
    "    print data['response']['total'], \" records available for\", searchterm\n",
    "    #create 2 unique files named after the searchterm\n",
    "    filename='_'.join(searchterm)\n",
    "    f2=open(filename+'.gdf','wb')\n",
    "    writer2 = csv.writer(f2)\n",
    "    #get all of the results\n",
    "    dr=data['response']['results']\n",
    "    edges=[]\n",
    "    edges2=[]\n",
    "    nodes={}\n",
    "    nodes2={}\n",
    "    for result in dr:\n",
    "        # Collect a list of tags associated with the current article\n",
    "        tags=[]\n",
    "        # Build up a list of unique node IDs, firstly using article IDs for the article-tag graph\n",
    "        if result['id'] not in nodes:\n",
    "            nodes[result['id']]=( result['id'],result[\"webTitle\"].encode('utf-8') )\n",
    "        # Now handle the article tags\n",
    "        for tag in result['tags']:\n",
    "            edges.append((result['id'],tag['id']))\n",
    "            # Build up a list of tags associated with this article\n",
    "            tags.append(tag['id'])\n",
    "            # Add the tags to the unique list of node IDs\n",
    "            if tag['id'] not in nodes:\n",
    "                nodes[tag['id']]= ( tag['id'], tag['webTitle'].encode('utf-8') )\n",
    "                nodes2[tag['id']]= ( tag['id'], tag['webTitle'].encode('utf-8') )\n",
    "        # For the tag-tag graph, we need to list the various tag combinations for this article\n",
    "        combos=map(list, combinations(tags, 2))\n",
    "        for c in combos:\n",
    "            edges2.append((c[0],c[1]))\n",
    "\n",
    "\n",
    "    # Print out the tag-tag nodelist\n",
    "    writer2.writerow(['nodedef>name VARCHAR','label VARCHAR'])\n",
    "    for node in nodes2:\n",
    "        n1,n2=nodes[node]\n",
    "        writer2.writerow([ n1, n2 ])\n",
    "\n",
    "    # Print out the tag-tag edgelist\n",
    "    writer2.writerow(['edgedef>from VARCHAR','to VARCHAR'])\n",
    "    for e1,e2 in edges2:\n",
    "        writer2.writerow([ e1, e2 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided on three relatively obscure and distinct geographies. Kamchatka Siberia, Baja Mexico, and Rabat Morocco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://content.guardianapis.com/search?q=Kamchatka&show-tags=keyword&&page-size=25&&order-by=relevance&api-key=d8d6f3e6-8a96-46b9-8681-d39b146def8c\n",
      "176  records available for Kamchatka\n"
     ]
    }
   ],
   "source": [
    "searchGuardian('Kamchatka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://content.guardianapis.com/search?q=Baja&show-tags=keyword&&page-size=25&&order-by=relevance&api-key=d8d6f3e6-8a96-46b9-8681-d39b146def8c\n",
      "280  records available for Baja\n"
     ]
    }
   ],
   "source": [
    "searchGuardian('Baja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://content.guardianapis.com/search?q=Rabat&show-tags=keyword&&page-size=25&&order-by=relevance&api-key=d8d6f3e6-8a96-46b9-8681-d39b146def8c\n",
      "378  records available for Rabat\n"
     ]
    }
   ],
   "source": [
    "searchGuardian('Rabat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Gelphi Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .gdf files have been exported and are loaded into the Gephi Environment. If you ran this analysis yourself you should see:\n",
    "\n",
    "K_a_m_c_h_a_t_k_a.gdf \n",
    "\n",
    "R_a_b_a_t.gdf\n",
    "\n",
    "B_a_j_a.gdf\n",
    "\n",
    "In Gephi:\n",
    "\n",
    "Step 1: Yifan Hu Layout transform\n",
    "\n",
    "Step 2: Symbolize by Eigenvector and degree centrality. Node size / text size by eigenvector and node color by degree. \n",
    "\n",
    "Step 3: Add Labels and perform label adjust filter.\n",
    "\n",
    "A link to the .gephi file [click here](https://github.com/RobertSellers/620_WEB/blob/master/Project_1.gephi).\n",
    "\n",
    "A link to a copy of the centrality analysis [click here](http://delineator.org/docs/Project1_gephi.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baja Network Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Baja Graph](https://raw.githubusercontent.com/RobertSellers/620_WEB/master/img/baja_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kamchatka Network Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kamchatka Graph](https://github.com/RobertSellers/620_WEB/raw/master/img/kamchatka_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rabat Network Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rabat Graph](https://github.com/RobertSellers/620_WEB/raw/master/img/rabat_graph.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
